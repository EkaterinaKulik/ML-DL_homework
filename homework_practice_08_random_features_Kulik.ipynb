{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYp0bXOFK-hP"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Дата выдачи: 30.01.2025\n",
        "\n",
        "Мягкий дедлайн: 23:59MSK 16.02.2025\n",
        "\n",
        "Жесткий дедлайн: 23:59MSK 23.02.2025\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
        "\n",
        "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Использование генеративных языковых моделей разрешено только в случае явного указания на это. Необходимо прописать (в соответствующих пунктах, где использовались, либо в начале/конце работы):\n",
        "- какая языковая модель использовалась\n",
        "- какие использовались промпты и в каких частях работы\n",
        "- с какими сложностями вы столкнулись при использовании генеративных моделей, с чем они помогли больше всего\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "### Формат сдачи\n",
        "Задания сдаются через систему anytask. Посылка должна содержать:\n",
        "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
        "\n",
        "Username — ваша фамилия и имя на латинице именно в таком порядке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY8vT0W_K-hR"
      },
      "source": [
        "### О задании\n",
        "\n",
        "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
        "\n",
        "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
        "\n",
        "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
        "$$\\tilde \\varphi(x) = (\n",
        "\\cos (w_1^T x + b_1),\n",
        "\\dots,\n",
        "\\cos (w_n^T x + b_n)\n",
        "),$$\n",
        "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
        "\n",
        "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
        "\n",
        "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
        "\n",
        "### Алгоритм\n",
        "\n",
        "Вам потребуется реализовать следующий алгоритм:\n",
        "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
        "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
        "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
        "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
        "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
        "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4aqFB03OxGpX"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_sGunb7K-hS"
      },
      "source": [
        "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YyG6dBfjK-hS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf834cc-4783-41b9-a29c-b87aee9ad604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train_pics.reshape(y_train.shape[0], -1)\n",
        "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMwLVadbxGpc"
      },
      "source": [
        "__Задание 0. (0.25 баллов)__\n",
        "\n",
        "**Вопрос:** зачем в алгоритме нужен метод главных компонент?\n",
        "\n",
        "**Ответ:** PCA используется в алгоритме для снижения размерности исходных данных. Это позволяет уменьшить вычислительные затраты на последующие этапы, такие как оценка гиперпараметра $\\sigma^2$, генерация новых признаков с помощью Random Fourier Features и обучение модели. PCA сохраняет основную информацию о данных, устраняя избыточные и коррелированные признаки, что может также способствовать улучшению обобщающей способности модели и снижению переобучения модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJNN55F7K-hT"
      },
      "source": [
        "__Задание 1. (3 балла)__\n",
        "\n",
        "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса в `homework_practice_08_rff.py` (допишите его и исправьте несостыковки в классе пайплайна) или написать свой интерфейс.\n",
        "\n",
        "Ваша реализация должна поддерживать следующие опции:\n",
        "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
        "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
        "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
        "\n",
        "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "WFN9tcuWmoRf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from homework_practice_08_rff import RFFPipeline, RandomFeatureCreator\n",
        "\n",
        "pipeline = RFFPipeline(n_features=1000, new_dim=50, feature_creator_class=RandomFeatureCreator)"
      ],
      "metadata": {
        "id": "1Jj8dQTnCt5Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "MLJmP31D50fM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "start_time_train = time.time()\n",
        "pipeline.fit(x_train, y_train)\n",
        "train_time = time.time() - start_time_train\n",
        "y_pred = pipeline.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Time for Random Fourier Features : {train_time:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s2yTFFN_-Lc",
        "outputId": "d9613954-230d-426c-baab-cebac059e9c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8574\n",
            "Time for Random Fourier Features : 63.398667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYqQUEi-K-hU"
      },
      "source": [
        "__Задание 2. (2.5 балла)__\n",
        "\n",
        "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
        "\n",
        "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучите градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost.\n",
        "\n",
        "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qN8LUlJgK-hV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d74818-c0fc-4888-c203-55cb949434e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Linear SVM: 0.7606\n",
            "Time for Linear SVM Random Fourier Features: 0.521150\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "import numpy as np\n",
        "subset_size = 1000\n",
        "subset_idx = np.random.choice(x_train.shape[0], subset_size, replace=False)\n",
        "x_train_subset, y_train_subset = x_train[subset_idx], y_train[subset_idx]\n",
        "\n",
        "linear_svm = LinearSVC()\n",
        "start_time_train_linear_svm = time.time()\n",
        "linear_svm.fit(x_train_subset, y_train_subset)\n",
        "train_time_linear_svm = time.time() - start_time_train_linear_svm\n",
        "y_pred_linear_svm = linear_svm.predict(x_test)\n",
        "\n",
        "accuracy_liniar_svm = accuracy_score(y_test, y_pred_linear_svm)\n",
        "print(f\"Accuracy for Linear SVM: {accuracy_liniar_svm:.4f}\")\n",
        "print(f\"Time for Linear SVM Random Fourier Features: {train_time_linear_svm:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "kernel_svm = SVC(kernel='rbf')\n",
        "start_time_train_kernel_svm = time.time()\n",
        "kernel_svm.fit(x_train_subset, y_train_subset)\n",
        "train_time_kernel_svm = time.time() - start_time_train_kernel_svm\n",
        "y_pred_kernel_svm = kernel_svm.predict(x_test)\n",
        "\n",
        "accuracy_kernel_svm = accuracy_score(y_test, y_pred_kernel_svm)\n",
        "print(f\"Accuracy for Kernel SVM: {accuracy_kernel_svm:.4f}\")\n",
        "print(f\"Time for Kernel SVM Random Fourier Features: {train_time_kernel_svm:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hU9qMnlfA0k",
        "outputId": "8e82dff9-4f2f-479a-80ef-cf251be5f4d2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Kernel SVM: 0.7915\n",
            "Time for Kernel SVM Random Fourier Features: 0.753179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "x_train_pca = pca.fit_transform(x_train_scaled)\n",
        "x_test_pca = pca.transform(x_test_scaled)\n",
        "\n",
        "lgbm = LGBMClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
        "start_time_train_lgbm = time.time()\n",
        "lgbm.fit(x_train_pca, y_train)\n",
        "train_time_lgbm = time.time() - start_time_train_lgbm\n",
        "y_pred_pca_lgbm = lgbm.predict(x_test_pca)\n",
        "\n",
        "accuracy_pca_lgbm = accuracy_score(y_test, y_pred_pca_lgbm)\n",
        "print(f\"PCA + LightGBM Accuracy: {accuracy_pca_lgbm:.4f}\")\n",
        "print(f\"Time for LightGBM : {train_time_lgbm:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2Hv8Ja5kY6y",
        "outputId": "9014ca34-a0ac-4d29-bf6d-0626b558873c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034575 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12750\n",
            "[LightGBM] [Info] Number of data points in the train set: 60000, number of used features: 50\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "[LightGBM] [Info] Start training from score -2.302585\n",
            "PCA + LightGBM Accuracy: 0.8661\n",
            "Time for LightGBM : 51.361381 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы сравнили между собой четыре метода: Linear SVM, Kernel SVM, Random Fourier Features и подход с понижением размерности с помощью PCA, за которым следует обучение градиентного бустинга.\n",
        "\n",
        "Если говорить об обычном SVM, то ядровой SVM показал более высокое качество по сравнению с линейным. Это ожидаемо, так как ядровой метод лучше отражает сложные нелинейные зависимости в данных. Однако стоит отметить, что обучение ядрового SVM заняло значительно больше времени, чем линейного (хотя длительное время обучения — это характерная особенность всего семейства SVM, особенно при использовании ядровых методов).\n",
        "\n",
        "Метод Random Fourier Features продемонстрировал качество лучше, чем линейный и даже ядровой SVM, что показывает его потенциал для аппроксимации нелинейных зависимостей с меньшими затратами. Однако время обучения RFF оказалось выше, чем у линейного SVM, и даже ядрового.\n",
        "\n",
        "Затем мы сравнили SVM и подход с понижением размерности с помощью PCA, за которым следовало обучение градиентного бустинга. Градиентный бустинг продемонстрировал значительно более высокое качество, чем SVM, что объясняется его способностью эффективно выявлять сложные зависимости в данных. Однако это потребовало большего времени на обучение по сравнению как с линейным, так и с ядровым SVM.\n",
        "\n",
        "Если говорить о сравнении градиентного бустинга и Random Fourier Features, то градиентный бустинг показал качество на одну десятую выше, чем RFF. Тем не менее, время обучения градиентного бустинга оказалось чуть большим, чем у RFF.\n",
        "\n"
      ],
      "metadata": {
        "id": "FvFdHvbUZDU0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6umjhWuK-hV"
      },
      "source": [
        "__Задание 3. (2 балла)__\n",
        "\n",
        "Проведите эксперименты:\n",
        "1. Помогает ли предварительное понижение размерности с помощью PCA?\n",
        "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
        "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c2QIHIMbK-hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07b0f37-110b-4205-ce83-5c87ccfea2d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without PCA: 0.1104\n",
            "Accuracy with PCA: 0.8590\n"
          ]
        }
      ],
      "source": [
        "pipeline_no_pca = RFFPipeline(n_features=1000, new_dim=50, feature_creator_class=RandomFeatureCreator, use_PCA=False)\n",
        "pipeline_no_pca.fit(x_train, y_train)\n",
        "y_pred_no_pca = pipeline_no_pca.predict(x_test)\n",
        "accracy_no_pca = accuracy_score(y_test, y_pred_no_pca)\n",
        "\n",
        "\n",
        "print(f\"Accuracy without PCA: {accracy_no_pca :.4f}\")\n",
        "print(f\"Accuracy with PCA: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Предварительное понижение размерности кардинально повысило качество модели (в 8 раз). Это происходит потому, что PCA удаляет шум в данных и устраняет мультиколлинеарность между признаками. Шумовые признаки часто не содержат полезной информации, но могут сбивать модель, особенно если их много. Устраняя их, PCA позволяет сосредоточиться на наиболее значимых признаках. Кроме того, уменьшение размерности помогает модели лучше обобщать данные и снижает риск переобучения, так как модель меньше подстраивается под избыточные или неинформативные признаки."
      ],
      "metadata": {
        "id": "Yqy4rcZWtPzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_features_list = [100, 500, 1000, 2000, 5000]\n",
        "accuracies = []\n",
        "\n",
        "for n in n_features_list:\n",
        "    pipeline = RFFPipeline(n_features=n, new_dim=50, feature_creator_class=RandomFeatureCreator)\n",
        "    pipeline.fit(x_train, y_train)\n",
        "    y_pred = pipeline.predict(x_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "plt.plot(n_features_list, accuracies, marker='o')\n",
        "plt.xlabel(\"Number of Features\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy depending on number of features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "3jCaf78kmSNy",
        "outputId": "295d5f5c-071b-4f80-e52a-52c62255f067"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Чем больше случайных признаков (RFF), тем выше качество модели. Однако после достижения порога в 2000 признаков наблюдается плато, и дальнейшее увеличение количества признаков практически не улучшает качество. Это связано с тем, что при достаточном числе признаков ядро становится достаточно хорошо аппроксимированным, и дальнейшее увеличение числа признаков только добавляет вычислительные затраты без значительного прироста точности."
      ],
      "metadata": {
        "id": "Pibu7iAxxMdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "subset_size = 1000\n",
        "subset_idx = np.random.choice(x_train.shape[0], subset_size, replace=False)\n",
        "x_train_subset, y_train_subset = x_train[subset_idx], y_train[subset_idx]"
      ],
      "metadata": {
        "id": "ehqY2ry21KWB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_svm = RFFPipeline(n_features=1000, use_PCA=True, classifier_class=SVC, classifier_params={\"kernel\": \"linear\"})\n",
        "pipeline_svm.fit(x_train_subset, y_train_subset)\n",
        "y_pred_svm = pipeline_svm.predict(x_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"Accuracy with SVM: {accuracy_svm:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFDM1sFFZSRV",
        "outputId": "7eac5f80-3bb9-4b3d-97a3-682fe75df552"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with SVM: 0.7560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. В данном эксперименте логистическая регрессия показала лучшее качество, чем линейный SVM, с разницей примерно в одну десятую долю. Более того, логистическая регрессия обучалась значительно быстрее, чем SVM, что делает ее предпочтительным выбором для данной задачи."
      ],
      "metadata": {
        "id": "Wl7BkfFAxjsj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVDWHCdrK-hX"
      },
      "source": [
        "__Задание 4. (Максимум 1.5 балла)__\n",
        "\n",
        "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет), n_features=new_dim и n_features < new_dim также должны работать, убедитесь в этом. Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HSxvGI9iK-hX"
      },
      "outputs": [],
      "source": [
        "from homework_practice_08_rff import OrthogonalRandomFeatureCreator\n",
        "\n",
        "pipeline_orth = RFFPipeline(n_features=1000, new_dim=50, feature_creator_class=OrthogonalRandomFeatureCreator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time_train_orth = time.time()\n",
        "pipeline_orth.fit(x_train, y_train)\n",
        "train_time_orth = time.time() - start_time_train_orth\n",
        "y_pred_orth = pipeline_orth.predict(x_test)\n",
        "\n",
        "accuracy_orth = accuracy_score(y_test, y_pred_orth)\n",
        "print(f\"Accuracy for Orthogonal Random Features: {accuracy_orth:.4f}\")\n",
        "print(f\"Time for Orthogonal Random Features: {train_time_orth:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crBR-L7X28jZ",
        "outputId": "a3386b32-c3f1-4c07-949b-050747681c7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Orthogonal Random Features: 0.8611\n",
            "Time for Orthogonal Random Features: 63.717056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы провели сравнение Random Fourier Features и Orthogonal Random Features с точки зрения качества модели и скорости обучения. В ходе экспериментов было выявлено, что ORF демонстрируют более высокое качество, чем RFF. Это объясняется тем, что признаки, сгенерированные с помощью ORF, ортогональны, что снижает избыточность и корреляцию между ними. Меньшая корреляция позволяет модели эффективнее использовать признаки и лучше улавливать зависимости в данных.\n",
        "\n",
        "Кроме того, обучение моделей на ORF оказалось быстрее, чем на RFF. Ортогонализация признаков снижает сложность численных вычислений и улучшает стабильность оптимизации, что приводит к более быстрой сходимости модели. Это преимущество особенно заметно при использовании линейных методов, которые чувствительны к взаимной зависимости признаков."
      ],
      "metadata": {
        "id": "dK_yqW5F3NPk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pc7-1jmK-hY"
      },
      "source": [
        "__Задание 5. (Максимум 1 балл)__\n",
        "\n",
        "Существует большое количество работ, где идея RFF развивается, предлагаются её обобщения (которые, по сути, выливаются в другие преобразования признаков, не обязательно уже тригонометрические). Возьмите любую из таких работ, кратко опишите идею, имплементируйте её и сравните качество с ORF и RFF, которые вы запрограммировали выше.\n",
        "\n",
        "Ссылки на статьи, где обсуждаются вариации RFF для разных ядер, можно найти в окрестности таблицы 1 в работе https://arxiv.org/pdf/1407.5599  \n",
        "\n",
        "___ссылка на работу___: https://vikas.sindhwani.org/RandomLaplace.pdf\n",
        "\n",
        "\n",
        "___описание идеи:___ авторы предлагают метод Random Laplace Features для аппроксимации семигрупповых ядер (semigroup kernel), применимых к гистограммам и другим неотрицательным данным. В отличие от Random Fourier Features, которые используют преобразование Фурье для создания сдвиг-инвариантных признаков, данный метод основывается на преобразовании Лапласа. Это позволяет эффективно аппроксимировать ядра, учитывающие аддитивную структуру неотрицательных данных, что особенно полезно в задачах компьютерного зрения и анализа гистограмм."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dWj-O2vjK-hY"
      },
      "outputs": [],
      "source": [
        "from homework_practice_08_rff import RandomLaplaceFeatureCreator\n",
        "\n",
        "pipeline_lap = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, feature_creator_class=RandomLaplaceFeatureCreator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time_train_lap = time.time()\n",
        "pipeline_lap.fit(x_train, y_train)\n",
        "train_time_lap = time.time() - start_time_train_lap\n",
        "y_pred_lap = pipeline_lap.predict(x_test)\n",
        "\n",
        "accuracy_lap = accuracy_score(y_test, y_pred_lap)\n",
        "print(f\"Accuracy for Random Laplace Features: {accuracy_lap:.4f}\")\n",
        "print(f\"Time for Random Laplace Features: {train_time_lap:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOJk_bKDFrKh",
        "outputId": "b314ecbb-cb33-43e8-b19b-323b9b89a176"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Random Laplace Features: 0.1000\n",
            "Time for Random Laplace Features: 6.315945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность метода Random Laplace Features оказалась в 8 раз ниже, чем у Random Fourier Features. RLF используют экспоненциальное распределение случайных весов, в отличие от гауссового в RFF. Это может приводить к менее равномерному покрытию пространства признаков, особенно если данные распределены неэкспоненциально, что ухудшает способность модели приближать сложные зависимости. Я бы также отметила, что ядро Лапласа менее гибкое, чем гауссовое, используемое в RFF. Гауссовые ядра хорошо аппроксимируют широкий спектр зависимостей, тогда как ядро Лапласа более ограничено в своей форме, что может объяснять сильное падение точности.\n",
        "\n",
        "При этом RLF обучается быстрее, поскольку его вычисления требуют меньше ресурсов."
      ],
      "metadata": {
        "id": "v86cWlYzNMxW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRCxWfhCxGpl"
      },
      "source": [
        "__Задание 6. (Максимум 2.5 балла)__\n",
        "\n",
        "Реализуйте класс ядровой Ridge регрессии (Лекция 13, $\\S 1.2$), для оптимизации используте градиентный спуск **[1 балл максимум]**, также добавьте возможность использовать аналитическую формулу **[1 балл максимум]**. Для градиентного спуска выпишите градиент ниже **[0.5 баллов максимум]**.\n",
        "Подумайте о том, как в формулах правильно учесть свободный коэффициент.\n",
        "\n",
        "Затем адаптируйте вашу реализацию RFF под задачу регрессии. Сравните вашу ядровую регрессию и RFF на синтетических данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaIKHa8nxGpm"
      },
      "source": [
        "Функция потерь:\n",
        "$$\n",
        "Q(w) = \\frac{1}{2} ||\\Phi \\Phi^T w - y||^2 + \\frac{\\lambda}{2} w^T \\Phi \\Phi^T w \\rightarrow \\min_w,\n",
        "$$\n",
        "где $\\Phi \\Phi^T = K$, $K = (k(x_i, x_j))_{i, j = 1}^{\\ell}$.\n",
        "\n",
        "Предсказание:\n",
        "$\n",
        "y(x) = k(x)^T w,\n",
        "$\n",
        "где $k(x)$ — вектор функций ядра от пар объектов $(x, x_i)_{i=1}^{\\ell}$.\n",
        "\n",
        "___Выведите градиент:___\n",
        "$$\n",
        "Q(w) = \\frac{1}{2} ||Kw - y||^2 + \\frac{\\lambda}{2} w^T K w \\rightarrow \\min_w,\n",
        "$$\n",
        "$$\n",
        "\\nabla Q(w) = K(Kw-y) + \\lambda K W\n",
        "$$\n",
        "$$\n",
        "\\nabla Q(w) = K K w - K y + \\lambda K w\n",
        "$$\n",
        "$$\n",
        "\\nabla Q(w) = K(Kw - y - \\lambda w)\n",
        "$$\n",
        "\n",
        "Вы можете изменять представленный шаблон в файле `homework_practice_08_kernel_regression.py` по своему усмотрению."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o0rqqfNQxGpn"
      },
      "outputs": [],
      "source": [
        "from homework_practice_08_kernel_regression import KernelRidgeRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "9loJCnRQ-0OJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.linspace(-2, 2, 1000).reshape(-1, 1)\n",
        "y = np.sin(3 * X).ravel() + 0.1 * np.random.randn(1000)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_krr = KernelRidgeRegression()\n",
        "\n",
        "start_time = time.time()\n",
        "model_krr.fit_closed_form(X_train, y_train)\n",
        "time_krr = time.time() - start_time\n",
        "\n",
        "y_pred_krr = model_krr.predict(X_test)\n",
        "\n",
        "mse_krr = mean_squared_error(y_test, y_pred_krr)\n",
        "\n",
        "print(f\"MSE for Kernel Ridge Regression: {mse_krr:.4f}\")\n",
        "print(f\"Time for Kernel Ridge Regression: {time_krr:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A-EHtf28jW5",
        "outputId": "902c0c3b-a106-45e2-def2-7722d9b03eb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for Kernel Ridge Regression: 0.0319\n",
            "Time for Kernel Ridge Regression: 0.074369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR"
      ],
      "metadata": {
        "id": "cdVljbkGEvBn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from homework_practice_08_rff import RFFPipeline, RandomFeatureCreator\n",
        "\n",
        "pipeline = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, classifier_class= SVR, feature_creator_class=RandomFeatureCreator)"
      ],
      "metadata": {
        "id": "nJ59bKhgE5Dw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time_train = time.time()\n",
        "pipeline.fit(X_train, y_train)\n",
        "train_time = time.time() - start_time_train\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "mse_rff = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE for Random Fourier Features: {mse_rff:.4f}\")\n",
        "print(f\"Time for Random Fourier Features : {train_time:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WCOsO8cCl2l",
        "outputId": "08976ff7-f6b7-46a5-da26-e680733326ef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for Random Fourier Features: 0.0104\n",
            "Time for Random Fourier Features : 0.757751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFF показал меньшую ошибку, что подтверждает его способность приближать сложные зависимости. Однако KRR обучался быстрее, так как использует аналитическое решение, тогда как RFF требует генерации случайных признаков и обучения линейной модели.\n",
        "\n",
        "На небольших выборках KRR может быть более выгодным из-за скорости, но при увеличении объема данных вычислительная сложность KRR возрастает, и RFF становится предпочтительнее. В целом, RFF демонстрирует хорошее качество и является конкурентоспособной альтернативой ядровым методам в регрессии."
      ],
      "metadata": {
        "id": "G7ZBbmWP1vSg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}